{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Networks Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The main benefit of using a Bayesian framework is that allows to propagate uncertainty to improve prediction and model reasoning. In this sense, is important that each component of a system computes an accurate estimate of uncertainty to later reflect the true uncertaint in the system.\n",
    "\n",
    "- Metrics must capture must capture the quantitative performance of the uncertainty the model is trying to measure.\n",
    "\n",
    "- Typical metrics should include uncertainty calibration plots and precision recall statistics of regression and classification algorithms.\n",
    "\n",
    "- Task-specific metrics include inspecting __test-log-predictive-probabilities a measure of how “surprised”__ the system output is on a test-set of known outcomes\n",
    "\n",
    "- It is most important to accurately __quantify the uncertainty of intermediate representations__, such as those from perception and scene prediction components.\n",
    "\n",
    "- The most important aspect is to correctly propagate uncertainty to the following layers so that we can make informed decisions. The final control output will be a hard decision. Therefore uncertainty metrics should focus on intermediate components and tasks such as perception, sensor fusion and scene prediction\n",
    "\n",
    "\n",
    "__Notes Taken from [1]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uncertainty is Used to track the dependability of the model.\n",
    "- In classificaiton problems, softmax probabilities are not enough to indicate whether the model is confident in its prediction.\n",
    "- A standard model would pass a point estimate through the softmax layer rather than the whole predictive distribution. This lead to high probabilities or high confidence on points far from data.\n",
    "    - __An example of Out-of-Distribution sample:__ In self-driving, if the training set of a model consisted of only images from highways and the model was then given an image of a dirt track, the model would return a steering angle but we would ideally require the model to have high uncertainty\n",
    "    - Noisy data $\\rightarrow$ Aleatoric uncertainty\n",
    "    - Model parameters uncertainty/variability $\\rightarrow$ Epistemic uncertainty\n",
    "    \n",
    "-  Means to estimate epistemic uncertainty is to perform __Bayesian Inference__.\n",
    "\n",
    "\n",
    "__Notes taken from [2]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epistemic Uncertainty Estimation with Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to use the posterior distribution $p(\\theta \\mid D)$ which is obatained from the data likelihood and the prior $p(\\theta)$ by applying Bayes theorem. The uncertainty in the model parameters is then marginalized out to obtain the posterior distribution:\n",
    "\n",
    "\\begin{equation}\n",
    "p(y^{*} \\mid x^{*}, D) = \\int p(y^{*} \\mid x^{*}, \\theta) p(\\theta \\mid D) d\\theta\n",
    "\\end{equation}\n",
    "\n",
    "The general intractable integral from above is approximated using $M$ Monte Carlo samples $\\theta^{i}$, ideally from the posterior. However, in practice is virtually impossible for DNNs to obtain samples from the true posterior $p(\\theta \\mid D)$. This requires approximation methods $q(\\theta) \\approx p(\\theta \\mid D)$ to be used [4].\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)}\n",
    "\\end{equation}\n",
    "\n",
    "The probability distribution of interest is the distribution p of the parameters θ after the data D is seen. p(D|θ) is the likelihood of the occurrence of data D given a model with parameters θ, p(θ) the prior, and p(D) the data distribution. Incorporating a prior belief in investigating a posterior state is a central characteristic of Bayesian reasoning. This prior is hence often referred to as domain knowledge [5].\n",
    "\n",
    "Learning for the BNN, amounts to computing the posterior distribution over the weights, $p(w \\mid D)$ through Bayes Rule. Because of the non-linearity introduced by the Neural Network architecture, the computation of the posterior cannot be done analytically. Hence varios approximation methods have been studied to perform inference with BNNs in practice [3], these methods are listed below:\n",
    "\n",
    "\n",
    "1. __Markov Chain Monte Carlo Methods__\n",
    "    - __Hamiltonian Monte Carlo (HMC):__\n",
    "    \n",
    "    Proceeds by defining a Markov chain whose invariant distribution is $p(w \\mid D)$ or $p(\\theta \\mid D)$. Relies on Hamiltonian dynamics to speed up the exploration of the space. HMC does not make any assumptions on the form of the posterior distribution, and is asymptotically correct. The result of HMC is a set of samples $w_{i}$ or $\\theta_{i}$ that approximate $p(w \\mid D)$ or $p(\\theta \\mid D)$ [3].\n",
    "    \n",
    "\n",
    "2. __Variation Inference Methods__\n",
    "\n",
    "    Proceeds by finding a Gaussian approximate distribution $q(w) \\approx p(w \\mid D)$ in a trade-off between approximation accuracy and scalability. The core idea is that $q(w)$ depends on some hyper-parameters that are then iteratively optimized by minimizing a divergence measure between $q(w)$ and $p(w \\mid D)$. Samples can then be efficiently extracted from $q(w)$ [3]\n",
    "    \n",
    "    - __Monte Carlo Dropout (MCD):__\n",
    "    \n",
    "    A particularly simple and scalable variant. The method entails using dropout also at __test time__, which can be interpreted as performing Variational Inference (VI) with a Bernoulli variational distribution. The approximate predictive posterior is obtained by performing $M$ stochastic forward passes on the same input [4].\n",
    "    \n",
    "    \\begin{equation}\n",
    "    p(y^{*} \\mid x^{*}, D):= \\frac{1}{M} \\sum_{i=1}^{M}p(y^{*} \\mid x^{*}, \\theta^{(i)}), \\space \\space \\theta^{(i)} \\sim p(\\theta \\mid D)\n",
    "    \\end{equation}\n",
    "    \n",
    "\n",
    "3. __Ensembling (considerend also non-bayesian)__\n",
    "\n",
    "    The parametric model $p(y \\mid x, \\theta)$ of the conditional distribution was created using a DNN $f_{\\theta}$, and learned multiple point estimates $\\{\\hat{\\theta}^{(m)}\\}_{m=1}^{M}$, by repeatedly minimizing the MLE objective $log\\space p(Y \\mid X, \\theta)$ with random initialization. They then averaged over the corresponding parametric models to obtain the predictive distribution:\n",
    "\n",
    "    \\begin{equation}\n",
    "    p(y^{*} \\mid x^{*}, D):= \\frac{1}{M} \\sum_{m=1}^{M}p(y^{*} \\mid x^{*}, \\theta^{(m)})\n",
    "    \\end{equation}\n",
    "\n",
    "    This approach is considered as a non-Bayesian alternative to predictive uncertainty estimation. However, since  $\\{\\hat{\\theta}^{(m)}\\}_{m=1}^{M}$, always can be seen as samples from some distribution $\\hat{q}(\\theta)$, we note that the previous equation is virtually identical to the equation described in MCD section. Ensembling can also be viewed as approximate Bayesian inference, where the level of approximation is determined by how well the implicit sampling distribution $\\hat{q}(\\theta)$ approximates the posterior $p(\\theta \\mid D)$ [4].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Metrics\n",
    "\n",
    "It has been shown that a networks that uses dropout is an approximation to a ___Gaussian Process___, where $\\mathbf{f}$ is the space of functions, $\\mathbf{X}$ is the training data and $\\mathbf{Y}$ is the training outputs. The expectation of $\\mathbf{y^{*}}$ is called the predictive mean of the model and the variance is the predictive uncertainty [2].\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\mathbf{y^{*}} \\mid \\mathbf{x^{*}}, \\mathbf{X}, \\mathbf{Y}) = \\int p(\\mathbf{y^{*}} \\mid \\mathbf{f^{*}}) \\space p(\\mathbf{f^{*}} \\mid \\mathbf{x^{*}}, \\mathbf{X}, \\mathbf{Y}) \\mathrm{d}\\mathbf{f^{*}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "For a regression network, the following equations are used to obtain an approximation of the predictive mean and variance of a Gaussian Process. Note that a network that uses dropout approximates a Gaussian Process [2].\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{E(y^{*})} \\approx \\frac{1}{T} \\sum_{t=1}^{T}\\hat{\\mathrm{y}}^{*}_{t} (\\mathrm{x^{*}})\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{Var(y^{*})} \\approx \\tau^{-1} \\mathbf{I}_\\mathrm{D} + \\frac{1}{T} \\sum_{t=1}^{T}\\hat{\\mathrm{y}}^{*}_{t}(\\mathrm{x^{*}})^T \\space \\hat{\\mathrm{y}}^{*}_{t} (\\mathrm{x^{*}}) - \\mathrm{E(y^{*})}^T \\mathrm{E(y^{*})}\n",
    "\\end{equation}\n",
    "\n",
    "The set ${\\mathrm{\\hat{y}}_{t} (\\mathrm{x^{*}})}$ of size $T$ is the results from $T$ stochastic forward passes through the network. It is important that the non-determinism from dropout is retained at prediction time to ensure different units will be dropped per pass through. Relating back to the Gaussian process, these are empirical samples from the approximate predictive distribution seen in Equation (5). $\\tau$ relates to the precision of the Gaussian process model, and is used in the calculation of the predictive variance [2]. $\\tau$ can be calculated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\tau = \\frac{l^{2} p}{2 N \\lambda}\n",
    "\\end{equation}\n",
    "\n",
    "where $l$ is a user-defined length scale, $p$ is the probability of units not being dropped, $N$ is the number of training samples and $\\lambda$ is multiplier used in the L2 regularization of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "***Softmax*** probabilities are a poor indicator of model prediction confidence, as they are the result of a single deterministic pass of a point estimate through the network. This situation can lead to high confidence on points far from the training data[2] that potentially wrong. The approaches to quantify classification uncertainty are:\n",
    "1. Variation Ratios\n",
    "2. Predictive Entropy\n",
    "3. Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. _Concrete Problems for Autonomous Vehicle Safety: Advantages of Bayesian Deep Learning_. R McAllister, Y. Gal, A. Kendall, et al. IJCAI 2017\n",
    "\n",
    "2. _Evaluating Quantification in End-to-End Autonomous Driving Control_. R Michelmore, M Kwiatkowska, Y Gal. 16/11/2018\n",
    "\n",
    "3. _Uncertainty Quantification with Statistical Guaranteees in End-to-End Autonomous Driving Control_. R Michelmore, M Wicker, L Laurenti, L Cardelli, Y Gal, M Kwiatkowska. 21/09/2019\n",
    "\n",
    "4. _Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer Vision_. F K Gustafsson, M Danelljan,  et al. 04/06/2019\n",
    "\n",
    "5. [_Probabilistic Deep Learning: Bayes by Backprop_. Felix Laumann.](https://medium.com/neuralspace/probabilistic-deep-learning-bayes-by-backprop-c4a3de0d9743)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
